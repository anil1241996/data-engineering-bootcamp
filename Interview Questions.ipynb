{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b245622b-6f13-4e1c-95ce-70a0a0556103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_âœ¨ Data Engineering Interview Questions 1st Round â€“ Hexaware âœ¨_**\n",
    "-  Difference between cache and persist\n",
    "-  Different types of secret scopes in Databricks\n",
    "-  How broadcast join works\n",
    "-  Program to print a string in reverse\n",
    "-  Different transformations used in Databricks\n",
    "-  What is a partition in Databricks\n",
    "-  Different file reading modes (e.g., fail fast, permissive, drop malformed)\n",
    "-  Common sources and destination formats used in ADB\n",
    "-  How to store data in different layers (Bronze, Silver, Gold)\n",
    "-  Difference between union and unionAll\n",
    "-  Where do you apply cache in the code? (with example)\n",
    "-  What is a partition, and how many are allocated by default?\n",
    "-  Different components of Databricks\n",
    "-  Difference between count(column) and count(*)\n",
    "-  Difference between distinct and dropDuplicates\n",
    "-  Difference between Fact and Dimension tables\n",
    "-  Different ways to access data from ADLS to ADB\n",
    "-  How to create a mount point\n",
    "-  How to improve performance in a slow-running Spark job\n",
    "-  What is autoscaling in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faecb17a-f41d-48f8-a2c1-a943dc0f4e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_ğ‚ğ¨ğ ğ§ğ¢ğ³ğšğ§ğ­ ğƒğšğ­ğš Eğ§ğ ğ¢ğ§ğğğ« ğˆğ§ğ­ğğ«ğ¯ğ¢ğğ° ğğ®ğğ¬ğ­ğ¢ğ¨ğ§ğ¬_**\n",
    "\n",
    "1ï¸âƒ£ In PySpark, find the highest salary in each department from a DataFrame with columns id, name, salary, and department.\n",
    "\n",
    "2ï¸âƒ£ In SQL, find employees who earn more than the average salary in their department.\n",
    "\n",
    "3ï¸âƒ£ In PySpark, read a CSV file from HDFS, drop rows with null values in a given column, and write it back as a Parquet file.\n",
    "\n",
    "4ï¸âƒ£ In SQL, get the second highest order amount for each customer from an orders table.\n",
    "\n",
    "5ï¸âƒ£ In PySpark, perform an inner join between two DataFrames on a common column and keep only matching rows.\n",
    "\n",
    "6ï¸âƒ£ In SQL, find the total transaction amount per user in the last 30 days.\n",
    "\n",
    "7ï¸âƒ£ In PySpark, convert a string timestamp column to TimestampType and extract year, month, and day into separate columns.\n",
    "\n",
    "8ï¸âƒ£ In SQL, retrieve the top 3 highest paid employees from each department.\n",
    "\n",
    "9ï¸âƒ£ In PySpark, calculate a running total of sales ordered by date for each store.\n",
    "\n",
    "1ï¸âƒ£0ï¸âƒ£ In SQL, find customers who have placed orders in every month of a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb3f45c6-6805-4a66-b08c-633e5d8c2b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_Walmart ğƒğšğ­ğš Eğ§ğ ğ¢ğ§ğğğ« ğˆğ§ğ­ğğ«ğ¯ğ¢ğğ° ğğ®ğğ¬ğ­ğ¢ğ¨ğ§ğ¬_**\n",
    "\n",
    "- 1. Explain how you created a data model during experimentation and A/B testing.\n",
    "- 2. How would you find the nth highest salary within each department using SQL? Why would you choose DENSE_RANK over RANK?\n",
    "- 3. How do you optimize Spark jobs that are taking longer than expected?\n",
    "- 4. How would you upload Parquet files to Azure Data Lake Storage using Python and Azure SDK?\n",
    "- 5. How does Airflow operate in a Kubernetes environment, and how does it store logs?\n",
    "- 6. Design an event-driven architecture for an analytics platform like Mixpanel.\n",
    "- 7. How would you perform an upsert in Delta Lake stored in Azure Data Lake using Spark?\n",
    "- 8. What is the difference between repartition() and coalesce() in Spark, and when would you use each?\n",
    "- 9. Explain Sparkâ€™s Tungsten and Catalyst Optimizer and how they improve performance.\n",
    "- 10. How would you handle synchronization and avoid deadlocks using threading or multiprocessing in Python? \n",
    "- 11. Compare Snowflake schema and Star schema in data warehousing.\n",
    "- 12. Explain how you would onboard a Delta Lake catalog to Azure Synapse for querying.\n",
    "- 13. How do you capture event logs and monitor performance on Databricks?\n",
    "- 14. What is the difference between Presto and Sparkâ€™s distributed architecture?\n",
    "- 15. Can Azure Synapse or Azure Data Explorer work with near real-time streaming data sources? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e763e3e-ecf0-4d0c-874e-05c444bf2b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_**ğŒğ¨ğ«ğ ğšğ§ ğ’ğ­ğšğ§ğ¥ğğ² ğğ²ğ­ğ¡ğ¨ğ§ ğƒğšğ­ğš ğğ§ğ ğ¢ğ§ğğğ« ğˆğ§ğ­ğğ«ğ¯ğ¢ğğ° ğğ®ğğ¬ğ­ğ¢ğ¨ğ§ğ¬**_\n",
    "- 1ï¸âƒ£ Write a Python program to reverse a string without using built-in functions\n",
    "- 2ï¸âƒ£ Given a list of integers, find the second largest element without sorting.\n",
    "- 3ï¸âƒ£ Implement a function to check if a string is a palindrome.\n",
    "- 4ï¸âƒ£ Write a Python program to count the frequency of each character in a string.\n",
    "- 5ï¸âƒ£ Given a list of numbers, remove all duplicates without using set().\n",
    "- 6ï¸âƒ£ Write a Python program to merge two sorted lists into one sorted list.\n",
    "- 7ï¸âƒ£ Implement a function to find the factorial of a number using recursion.\n",
    "- 8ï¸âƒ£ Write a Python program to find all prime numbers between 1 and 100.\n",
    "- 9ï¸âƒ£ Given a list of integers, find the pair whose sum is closest to a given target.\n",
    "- ğŸ”Ÿ Implement a function to flatten a nested list (e.g., [1, [2, [3, 4]], 5] â†’ [1, 2, 3, 4, 5])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c076539c-baa4-406f-a00a-fa8e1cd85f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_SQL Questions_**\n",
    "-  Retrieve the top 3 revenue-generating products within each category.\n",
    "-  Identify products with revenue higher than the average across all products.\n",
    "-  Use LAG() and CASE to find customers showing month-over-month spending growth.\n",
    "-  Mark each userâ€™s first and last transaction in a dataset.\n",
    "-  Find employees under the same manager who also earn identical salaries.\n",
    "\n",
    "**_Python Questions_**\n",
    "-  Reverse a list manually (without .reverse() or slicing).\n",
    "-  Convert a mixed string like â€œabc123xyzâ€ to uppercase without using .upper().\n",
    "-  Extract keys from a dictionary where values are even.\n",
    "-  Check if two strings are anagrams using a custom function.\n",
    "-  Create a frequency map for each character in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b68a85f-0c93-4537-ba83-d11d98a1d937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8403350092199377,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Interview Questions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
