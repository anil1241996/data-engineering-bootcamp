{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b245622b-6f13-4e1c-95ce-70a0a0556103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_✨ Data Engineering Interview Questions 1st Round – Hexaware ✨_**\n",
    "-  Difference between cache and persist\n",
    "-  Different types of secret scopes in Databricks\n",
    "-  How broadcast join works\n",
    "-  Program to print a string in reverse\n",
    "-  Different transformations used in Databricks\n",
    "-  What is a partition in Databricks\n",
    "-  Different file reading modes (e.g., fail fast, permissive, drop malformed)\n",
    "-  Common sources and destination formats used in ADB\n",
    "-  How to store data in different layers (Bronze, Silver, Gold)\n",
    "-  Difference between union and unionAll\n",
    "-  Where do you apply cache in the code? (with example)\n",
    "-  What is a partition, and how many are allocated by default?\n",
    "-  Different components of Databricks\n",
    "-  Difference between count(column) and count(*)\n",
    "-  Difference between distinct and dropDuplicates\n",
    "-  Difference between Fact and Dimension tables\n",
    "-  Different ways to access data from ADLS to ADB\n",
    "-  How to create a mount point\n",
    "-  How to improve performance in a slow-running Spark job\n",
    "-  What is autoscaling in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faecb17a-f41d-48f8-a2c1-a943dc0f4e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_𝐂𝐨𝐠𝐧𝐢𝐳𝐚𝐧𝐭 𝐃𝐚𝐭𝐚 E𝐧𝐠𝐢𝐧𝐞𝐞𝐫 𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧𝐬_**\n",
    "\n",
    "1️⃣ In PySpark, find the highest salary in each department from a DataFrame with columns id, name, salary, and department.\n",
    "\n",
    "2️⃣ In SQL, find employees who earn more than the average salary in their department.\n",
    "\n",
    "3️⃣ In PySpark, read a CSV file from HDFS, drop rows with null values in a given column, and write it back as a Parquet file.\n",
    "\n",
    "4️⃣ In SQL, get the second highest order amount for each customer from an orders table.\n",
    "\n",
    "5️⃣ In PySpark, perform an inner join between two DataFrames on a common column and keep only matching rows.\n",
    "\n",
    "6️⃣ In SQL, find the total transaction amount per user in the last 30 days.\n",
    "\n",
    "7️⃣ In PySpark, convert a string timestamp column to TimestampType and extract year, month, and day into separate columns.\n",
    "\n",
    "8️⃣ In SQL, retrieve the top 3 highest paid employees from each department.\n",
    "\n",
    "9️⃣ In PySpark, calculate a running total of sales ordered by date for each store.\n",
    "\n",
    "1️⃣0️⃣ In SQL, find customers who have placed orders in every month of a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb3f45c6-6805-4a66-b08c-633e5d8c2b96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_Walmart 𝐃𝐚𝐭𝐚 E𝐧𝐠𝐢𝐧𝐞𝐞𝐫 𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧𝐬_**\n",
    "\n",
    "- 1. Explain how you created a data model during experimentation and A/B testing.\n",
    "- 2. How would you find the nth highest salary within each department using SQL? Why would you choose DENSE_RANK over RANK?\n",
    "- 3. How do you optimize Spark jobs that are taking longer than expected?\n",
    "- 4. How would you upload Parquet files to Azure Data Lake Storage using Python and Azure SDK?\n",
    "- 5. How does Airflow operate in a Kubernetes environment, and how does it store logs?\n",
    "- 6. Design an event-driven architecture for an analytics platform like Mixpanel.\n",
    "- 7. How would you perform an upsert in Delta Lake stored in Azure Data Lake using Spark?\n",
    "- 8. What is the difference between repartition() and coalesce() in Spark, and when would you use each?\n",
    "- 9. Explain Spark’s Tungsten and Catalyst Optimizer and how they improve performance.\n",
    "- 10. How would you handle synchronization and avoid deadlocks using threading or multiprocessing in Python? \n",
    "- 11. Compare Snowflake schema and Star schema in data warehousing.\n",
    "- 12. Explain how you would onboard a Delta Lake catalog to Azure Synapse for querying.\n",
    "- 13. How do you capture event logs and monitor performance on Databricks?\n",
    "- 14. What is the difference between Presto and Spark’s distributed architecture?\n",
    "- 15. Can Azure Synapse or Azure Data Explorer work with near real-time streaming data sources? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e763e3e-ecf0-4d0c-874e-05c444bf2b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_**𝐌𝐨𝐫𝐠𝐚𝐧 𝐒𝐭𝐚𝐧𝐥𝐞𝐲 𝐏𝐲𝐭𝐡𝐨𝐧 𝐃𝐚𝐭𝐚 𝐞𝐧𝐠𝐢𝐧𝐞𝐞𝐫 𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧𝐬**_\n",
    "- 1️⃣ Write a Python program to reverse a string without using built-in functions\n",
    "- 2️⃣ Given a list of integers, find the second largest element without sorting.\n",
    "- 3️⃣ Implement a function to check if a string is a palindrome.\n",
    "- 4️⃣ Write a Python program to count the frequency of each character in a string.\n",
    "- 5️⃣ Given a list of numbers, remove all duplicates without using set().\n",
    "- 6️⃣ Write a Python program to merge two sorted lists into one sorted list.\n",
    "- 7️⃣ Implement a function to find the factorial of a number using recursion.\n",
    "- 8️⃣ Write a Python program to find all prime numbers between 1 and 100.\n",
    "- 9️⃣ Given a list of integers, find the pair whose sum is closest to a given target.\n",
    "- 🔟 Implement a function to flatten a nested list (e.g., [1, [2, [3, 4]], 5] → [1, 2, 3, 4, 5])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c076539c-baa4-406f-a00a-fa8e1cd85f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_SQL Questions_**\n",
    "-  Retrieve the top 3 revenue-generating products within each category.\n",
    "-  Identify products with revenue higher than the average across all products.\n",
    "-  Use LAG() and CASE to find customers showing month-over-month spending growth.\n",
    "-  Mark each user’s first and last transaction in a dataset.\n",
    "-  Find employees under the same manager who also earn identical salaries.\n",
    "\n",
    "**_Python Questions_**\n",
    "-  Reverse a list manually (without .reverse() or slicing).\n",
    "-  Convert a mixed string like “abc123xyz” to uppercase without using .upper().\n",
    "-  Extract keys from a dictionary where values are even.\n",
    "-  Check if two strings are anagrams using a custom function.\n",
    "-  Create a frequency map for each character in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b68a85f-0c93-4537-ba83-d11d98a1d937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8403350092199377,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Interview Questions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
